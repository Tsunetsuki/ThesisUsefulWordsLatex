% 				\item Sentence importance evaluation
% 				\item Capturing text as coherent unit instead of sentences which are independent of each other
% 				\item Active vs passive utility: Ideas for active utility estimation
% 				\item Compound splitting
% 				\item Lemmatization
% 				\item n-grams
% 				\item Multilinguality
%
We have seen in the previous chapter that our approach to list generation outperforms frequency-based metrics when \todo{insert exact circumstances}.
This final chapter discusses several possible improvements to our approach and the research around it, which were not possible within the scope of this work due to time constraints.

\section{Lemmatization}
The vocabulary lists we compiled were dictated by the tokens provided by the tokenizer.
With this approach, each unique combination of letters is regarded as an independent word, including variations of a particular word such as "house" and "houses", "look", "looks", "looked".
However, in textbooks, vocabulary lists are usually organized by headwords or \textit{lemmas}, that is, the variations as seen above are considered as a single word.
To compile more useful vocabulary lists, we recommend that words which derive from the same lemma be treated as the same word.
"Treating" here includes the masking of tokens for model-agnostic XAI methods, as well grouping words together by their lemma in the post-processing of vocabulary lists which are produced by model-specific approaches.

\section{Active vs. Passive Utility}
This work has exclusively focused on the utility of words for understanding existing texts, however, one can also consider the utility of a word for active speaking and writing:
One obvious difference is that, when there are two synonyms, it suffices to know one of the two for active speaking, but for passive understanding, both must be learned.

\section{Multilinguality}
While we have made an effort to make our implementation handle as many languages as possible, we have only tested it on English corpora.
An extension of this work should include evaluation on the other languages supported by the data pipeline.

\section{Distinction of Homonyms}
Some words can have multiple meanings:
An example of this is the word \textit{can}, which can signify either a container (a tin can) or the modal verb (to be able to do something).
Such words are called \textit{homonyms}.
In order to produce more useful lists of vocabulary, distinction between the different meaning of such words could be a useful component, especially when one of the meanings is more common than the other.


\section{Better XAI Methods}
\todo{write}








