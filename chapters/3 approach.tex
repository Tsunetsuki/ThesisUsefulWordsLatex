This chapter describes in detail our approach for word utility evaluation fulfilling the goal stated in chapter \ref{seq:statement-of-goal}.
The problem is first put into terms of mathematical objects in chapter \ref{seq:problem-statement-formal}.

We then describe a hypothetical experiment that could be performed to evaluate word utility using human feedback in chapter \ref{seq:human-efficiency-testing}
After pointing out the unfeasibility of such a testing method, we suggest ways to perform the experiment with AI models instead of humans as the test subject, using the technological building blocks referred to in chapter \ref{seq:basic-nlp-concepts}.

\section{Problem Statement for Word Utility Evaluation} \label{seq:problem-statement-formal}

% the following terms have been defined before can should be used now
% language context
% utility
% proxy task

To repeat the introductory sentence of chapter \ref{seq:statement-of-goal}:
The aim of this work is to find words that have the maximum \textit{utility} given a particular \textit{language context} by means of \textit{proxy tasks}.
Keeping in mind that this is done in order to sort words into vocabulary lists that can be used by language learners, we can conclude that the output of a proposed solution to this problem would be an \textbf{ordered list of words}. The following formula gives a more precise idea of the aim and the variables involved.

Since utility is defined in terms of language ability, we first need a way to put a number on the language ability of a test subject. This is done by means of a proxy task: We can imagine a human test subject taking a language exam as a proxy task to find out their language ability:

\begin{align*}
	t: \text{Human} \to [0, 1] \\
	t (s) \mapsto p            \\
\end{align*}
where $s$ is the test subject and $t$ is the proxy task, with a possible score $p$ between zero and one.

We can imagine many variables going into this function, such as the time when the test is taken (hopefully the human's performance would increase over time). However, this thesis addresses vocabulary learning, and so the vocabulary of the test subject is provided as an additional parameter into the function

Let $W$ be the set of all words in the language.
\begin{align*}
	t: \text{Human}, 2^{W}\to \mathbb{R} \\
	t (s, V) \mapsto p                   \\
\end{align*}
where $V \in W$ is the vocabulary of the test subject.

We now have a function from the vocabulary to the score in the proxy task (the proxy metric for language ability).
Using the proxy task function, we can define a measure of efficiency of an ordered list of vocabulary $l$ containing elements from $W$.
The efficiency reflects how quickly a learner improves their language ability if they learn words in the order of the list, measured as a proportion $p_{aim}$ of the maximum achievable performance $p_{max} = t(s,W)$ (knowing all words in the language).
It is the number of words which must be learned from the vocabulary list to bring the performance above the threshold:

Let
\begin{align*}
	l        & := (w_1, w_2, \dots, w_n) \quad \text{where } w_i \in W \text{ and } w_i \neq w_j \text{ for } i \neq j. \\
	V_{l, k} & := \{w_i \mid i \leq k\}                                                                                 \\
	p_{aim}  & \in  [0, 1]                                                                                              \\
\end{align*}

Then
\begin{align*}
	e_{t}(s, l, p_{aim}) \mapsto ( -1 )  \cdot  \min\{ k \mid  t(s,  V_{l, k}) \geq p_{aim} \cdot t(s, W)\} \\
\end{align*}
The term contains a multiplication with $-1$ such that an efficient list achieves a higher efficiency.

And with this definition of efficiency, we can define the condition for an optimal vocabulary list given a particular $p_{aim}$:
\begin{align} \label{eq:opt-vocab-list}
	l_{opt, t} (s, p_{aim}) = \argmax_{l} e(s, l, p_{aim})
\end{align}

Finding vocabulary lists that approximate an optimal list according to formula \ref{eq:opt-vocab-list} is the aim which the rest of this work is dedicated to.


\section{Experimental Setup: Measuring Word Utility as Ability Improvement in Humans} \label{seq:human-efficiency-testing}

\contentdescription{state utility in terms of language ability improvement
	aim is not just to evaluate, but also efficiently find lists of vocab
	give problems that is faced when trying to test this approach with human test subjects: no repeatability, high costs
}

With the formula \ref{eq:opt-vocab-list}, we now have set our goal more concretely.
We are left with the question of how to actually make candidate vocabulary lists, and test them for efficiency.
Let us first consider how we could measure the efficiency of one vocabulary list of 3000 words:

We would need to find a human test subject who does not know any words of the target language at the outset.
We would then make the subject learn the words from the list one by one, and test their language ability in regular intervals to see if their desired threshold has been reached.
This disregards the fact that knowing all words in the language would not necessarily mean the performance would reach 1, but assuming a normal school test that is not an issue.

While this test setup might take a long time to complete depending on the desired threshold, it is still feasible.
But if we wish to analyze the same subject's performance learning from a second vocabulary list to compare the lists' efficiencies, there is an unavoidable issue:
The test subject cannot completely forget the words they have learned in the first run.
The experiment is thus not repeatable.
If we increase the number of test subjects so each vocabulary list is learned by a new subject, we introduce differences in capabilities between test subjects and the cost of the experiment also quickly increases.

However, this theoretical test setup could be feasible using a non-human test subject:
Using AI models and Explainable AI to analyze their interaction with language, we could not only evaluate, but even compile lists with drastically reduced costs.
I shall lay out this approach in the remaining sections of this chapter.

\section{AI-Simulated Learner} \label{seq:ai-simulated-learner}
\contentdescription{I view AI models as containers of language knowledge. We can perform studies on it as though it were human, gaining knowledge "from the viewpoint of an entity interacting with language"}

This work is interested in finding vocabulary lists that language learners can use to gain linguistic competence in their chosen field in the least possible time.
Chapter \ref{seq:problem-statement-formal} has specified how with the help of a proxy task, we can define this efficiency.
Chapter \ref{seq:human-efficiency-testing} has laid out a theoretical approach for how with human test subject, one could test the efficiency of a vocabulary list.
However, we have established that the experiment is not easy to set up consistently, as it cannot be repeated with the same test subject on different lists and a large pool of test subjects lowers the comparability of the scores.

To circumvent this issue, this work proposes the following core idea:
By replacing the human test subject with an AI model, it could be possible to execute the experiment described in chapter \ref{seq:human-efficiency-testing} consistently and economically:

In recent years AI models such as ChatGPT \tocite{ChatGPT}, Gemini, DeepSeek, BERT have become highly adept at fulfilling language-related tasks such as Language Modeling \tocite{LLMs}, Named Entity Recognition, Sentiment Detection.

It may be said that they possess an understanding of language in a behaviorist sense.

These AI models are trained on one or more specific NLP tasks.
If we run the model on a specific corpus and mask some of the words in the input, it is expected that the performance will decrease in comparison to the full input.
However, presumable some words will have a larger impact on the performance than others.
So to test the efficiency of a vocabulary list, we could let the AI model perform its NLP task on the corpus.
At the start, we mask all of the tokens in the input to simulate a language learner who is a complete beginner and thus knows no words in their target language.
We can then progressively unmask words in the input, and each time run the AI on the corpus to check the updated (and presumably improved) performance.
This will yield a plot of performance over unmasked words which will tell us how quickly the performance improves with unmasked words.
A plot with low initial performance increase will betray an inefficient vocabulary list, whereas a quickly increasing performance should correspond to an efficient vocabulary list.

This is a cheap option when compared to using a human test subject and unlike the human, the AI model has no memory of previous tests, meaning we can run the experiment consistently every time.

The experiment described above necessarily requires data to be performed, in the form of a corpus.
We can suppose that both the corpus and the NLP task performed by the model will influence how quickly the AI model's performance increases with a given vocabulary list:

For example, to perform Sentiment Detection, words relating to emotion such as "hate", "like", "amazing" will matter more than if the task is related to Information Extraction, such as Temporal Tagging.

The corpus will have a more obvious influence on the performance, since corpora differ in many aspects such as formality, topic, and format of the text, all of which may be closely influenced by the learning reason of a language learner.
Thus, by choosing an appropriate corpus, we can test performance on language that is similar to the language in which a learner wishes to improve their understanding.



Thus, with this model in mind, we can translate some of the concepts introduced in chapters \ref{seq:statement-of-goal} into technical components to see how we could implement a technical solution to the problem of analyzing the utility of words.
Table \ref{table:concept-implementation-correspondence} shows the correspondences between the concept and the technical component.

\begin{table}[ht]
	\centering
	\begin{tabularx}{\textwidth}{|X|X|}
		\hline
		\textbf{Abstract concept}        & \textbf{Implementation}            \\
		\hline
		Test subject                     & AI model                           \\
		\hline
		Language ability                 & Performance in NLP task            \\
		\hline
		Language context                 & Corpus                             \\
		\hline
		Analysis of language interaction & XAI method                         \\
		\hline
		Word utility                     & Impact of word on task performance \\
		\hline
	\end{tabularx}
	\caption{Correspondence of abstract concepts to parts of implementation.}
	\label{table:concept-implementation-correspondence}
\end{table}


\section{Generating Lists of Useful Vocabulary}
The previous chapter describes an approach for evaluating the efficiency of vocabulary lists for learning in a specific context.
While it can be seen as an improvement on the human setup because of its improved consistency and economy, it describes only the process of evaluation, not generation.
Actually finding optimal vocabulary lists is theoretically possible by testing every possible vocabulary list with all words in the language.

In practice, however, this would require an enormous amount of computational resources:

If we wish to find the most efficient list of 1,000 words, and we take the most frequent 20,000 words in the language as candidates for members of this list, there is a total number of $P(20000, 1000) = \frac{20000!}{19000!}$ possible vocabulary lists to be tested.
Since every one of these test consists of running the proxy task with a vocabulary which is a subset taken from the first $n$ elements where $n \in [0, 1]$, and all of the subsets will appear in the runs of many vocabulary lists, we can optimize this by running the task with every vocabulary with a cardinality between 0 and 1,000, which would be
$
\sum_{k=0}^{1000} \binom{20000}{k} \approx \frac{1}{2} \times 2^{20000} = 2^{19999}
$ runs of the proxy task.
.
This is still an unfeasible amount of computation. 

It is therefore clear that finding optimal vocabulary list is much too expensive to be done without approximation.
As approximations, we suggest XAI to extract information about the linguistic skills of AI models, and the following chapters illustrate this approach.

\section{Knowledge Extraction from AI Model with XAI}
\contentdescription{Advances in XAI, explain various approaches.}

The previous chapters have shown the challenges in evaluating the efficiency of vocabulary lists with human test subjects, and suggested a way to use AI models in connection with NLP tasks as a way to make a consistent and repeatable approach.
The problem of generating the lists in the first place still remains, however.

The guiding question of this thesis is:
\textit{"Which words provide the most language understanding in a particular context?"}.
Simulating the learner with AI models in the way described in chapter \ref{seq:ai-simulated-learner} turns this question into:
\textit{"Which words improve the performance of the AI model in the NLP task for a given corpus?"}.

This question is very close to the questions that the field of Explainable AI seeks to answer.
A typical question of Explainable AI would be:
\textit{"Why for a given input, did the model arrive at its output?"}.
If the input takes the form of natural language, we can be more specific:
\textit{"Which words in the input made the model arrive at its output?"}

By using XAI and answering this questions across the entire corpus, we can find out which words are the most essential for the AI model to perform its task in the corpus.
If the words found in this way are close to those that would provide the most utility to a human learner as well, they could be used to create very efficient vocabulary lists as well.


We therefore propose a framework to extract useful words which has the following main components:
\begin{itemize}
	\item Corpus
	\item (Pretrained) AI model
	\item NLP task
	\item XAI method
\end{itemize}

In the implementation, we will present various choices for these components, and argue for some to be used over others, with the aim of making the utility estimated by the framework align as much as possible with utility to human learners.

%
% It is readily seen that these components are not independent of each other.
% Some completely determine the choice of another, while others limit the selection of the other components.
% 	[describe dependencies between components]
% Task $\rightarrow$ model $\rightarrow$ tokenizer $\rightarrow$ words.
%
% must investigate comparability of results later.

% (also corpus $\rightarrow$ task)
% \subsection{Preliminary Investigations of Integrity}
% The core idea this paper is to evaluate word utility by investigating a function (in the form of an AI model) that presumably represents some level of understanding of the language and checking which inputs (words) have the biggest influence on either the input or the model's internal state.
% To ensure the function does possess this understanding, it is necessary to first ensure that the output of the model corresponds reliably to the ground truth, in other words, to tests the performance of the model on the specific data that will later be used to investigate the model itself.
%
% \todo{A lot of prelim. test results, for example, first tests of NSP model on opensubs sentences show low reliability. Might also have to move this section to end (or in "results" chapter?)}
%


%
%
% \section{Experimental Setup with AI Technology}
% With the experimental setup described in chapter \ref{seq:human-efficiency-testing}, we established a way to test the efficiency of a vocabulary list with a human test subject.
% Now that we have introduced the idea of performing the experiment with an AI model instead, let us examine how such an approach would work:
% Chapter \ref{table:concept-implementation-correspondence} suggested ways that we could use technological components to stand in for abstract concepts.
%
%
% \todo{ restate math problem definition with components replaced by AI}
%
%

\section{TO BE SORTED OR DELETED}
Let us examine examples of how utility may be defined:
In the question "Would you like some coffee?", the most important part is "coffee".
If we replaced the entire sentence with "coffee?", the meaning becomes less clear, but it is still possible to guess what is meant.
If, however, we replace the sentence with "would?", there is so little information in the sentence that it becomes impossible to guess the meaning.
To identify which words are important to understand the question, we could ask a human to point them out.
However, this is not very quantifiable and the answer is likely to be influenced by bias.
We could try removing some of the words in the sentence and see if a human hearing the question can still answer appropriately.
While this removes some of the bias, there are still issues with this approach:
Going through all possible permutations of the sentence would take a great amount of time to perform, and the same test subject cannot process one permutation without being influenced by the past experiences:
If we go through "would?", "you?", "like?", "some?", "coffee?" in sequence, the test subject would have full knowledge of the sentence by the time the last item is asked.
These problems can be alleviated by using AI models: They are cheaper to perform tests on than humans, and can be employed in such a way as to answer the question without being influenced by the previous questions each time.

\todo{Explain approach where a model is trained on small set of words and performance is evaluated. But too costly.}


While the models achieving state-of-the-art performance (neural networks) are black boxes for the most part, they are easier to understand than human decisions and the field of Explainable AI has produced various approaches to gauge the importance of inputs to the model.
Explainable AI has the explanation of the decisions of AI models as its aim.
This means that when analyzing the decisions of AI models by reducing them to human-understandable rules or by observing which words are the most important for the AI to fulfill its tasks, we are not technically observing rules of objective truth, but only the behavior which the AI has learned to perform its task.
If we try to extract truthful knowledge about language from the AI, we are relying on the assumption that the AI has learned rules that correspond to linguistic reality.
However, in the case of state-of-the-art models, we know the performance of such models to meet certain standards, which supports the above assumption.





\section{NLP Tasks}
The choice of NLP tasks employed to test a XAI-based approach for word utility estimation is a crucial step:
Since we are trying to estimate the utility a word a word has to language understanding, the NLP tasks should reflect language understanding as much as possible.
A good place to start looking for such tasks are those which are typically employed for pre-training NLP models:
Pre-training tasks are used to first endow the AI model with a general understanding of the language, before using transfer learning to specialize it for a more specific downstream task.
Such tasks must necessarily be general and require general language understanding, since training the model with them is supposed to provide a solid basis for a wide variety of NLP tasks.
Another benefit of using pre-training tasks is that their training is unsupervised, meaning there is no need to manually label data.
\todo{Look at various pre-training tasks, preferably those used by state-of-the-art AI models}
\todo{include free availability for AI models in their justification}

\subsection{NLP Pre-Training Tasks Used by State-of-the-Art AI Models}
This section takes a look at the pretraining process of recent state-of-the-art LLM models which have made public their training process.
Both the NLP tasks and the kind of data is considered.


\begin{description}
	\item[GPT-4] \cite{openaiGPT4TechnicalReport2024}

	      Task: Language modeling (see next section).

	      Data: Not disclosed in detail, according to the original paper, the model was trained "using both publicly available data (such as internet data) and data licensed from third-party providers".
	\item[GPT-3] \cite{brownLanguageModelsAre2020}
	      GPT-3 is a model that does not rely on transfer learning to apply its linguistic understanding to new tasks; instead, it uses zero-shot and few-shot learning to perform tasks it was not specifically trained for.

	      Task: Language modeling (same as GPT-2 \cite{radfordLanguageModelsAre2019})

	      Data: Common Crawl, WebText2, Books1, Books2, Wikipedia \todo{link sources?}
	\item[LLama 3.3] \cite{LlamamodelsModelsLlama3_3}


	      Task: Meta did not make public the training process for Llama 3.3.

	      Data: "data from publicly available sources"
\end{description}

\subsection{Tasks Considered}
\begin{description}
	\item[Next Sentence Prediction]
	      In this task, the AI model takes as input two sentences and predicts a probability for the second sentence being the successor of the first sentence in their source text.
	      Advantages for this task for our purposes is that such a dataset is easy to generate, as it merely requires a corpus of sentences that follow from each other, which is easily obtained from Wikipedia articles, film subtitles, or any other continuous text.

	\item[Text summarization]
	      This task involves summarizing a given text, in other words, writing a shorter version of the input text while still conveying as much of the information from the original text as possible.
	      Summarizing texts seems to require a high level of "understanding" of the text and would thus seem to be good choice for testing whether ablating certain words from the text would have detrimental effect on the model performance.
	      Unfortunately, this task requires hand-labeled datasets and is thus not a good candidate if we aim to find approaches which can be implemented in many different languages, as there is a dearth in data in many of the less-studied languages of the world.

	\item[Masked language modeling (aka. "cloze task")]
	\item[Causal language modeling (aka. Next token prediction)]
	\item[Sentence order prediction]
	\item[Sentence embeddings]
	      Sentence embeddings take the approach of transforming words into meaningful vectors and extend it to whole sentences.
	      This "task" differs from the others in that we do not measure differences in performance when the input is perturbed; but rather a distance between the embedding vectors themselves.
	      This justification for such an approach is that sentences whose meaning is very different should end up further apart from each other in the vector space once embedded.
	      This brings several advantages:
	      This approach can be performed on any corpus containing distinct sentences.
	      These corpus does not have to be document-level, and sentences need not be consecutive.
	      To make this a task on which XAI methods can be applied, we can define a distance from the original token
\end{description}

\subsection{Sentence Embedding Methods}

\begin{description}
	\item[LASER] \cite{artetxeMassivelyMultilingualSentence2019}
	\item[BERT] \cite{reimersMakingMonolingualSentence2020}
\end{description}

\subsection{Data Required for Each NLP Task}
The various NLP tasks employed require certain types of corpora to be employed properly:

\begin{itemize}
	\item[Next sentence prediction]
	      Requires a corpus that contains consecutive sentences.
	      Furthermore, NSP typically predicts whether two sentences follow each other in a document, not a dialogue (see the data on BERT training \cite{kentonBertPretrainingDeep2019}).
	      This excludes movie subtitles from the possible corpora for this task.

\end{itemize}

\section{XAI Methods}

The XAI methods used in this work are the following:
\begin{itemize}
	\item Attention as Explanation
	      Advantages:
	      Model only needs to be run once per sentence.
	      Longer sentences do not lead to a much longer calculations
	      Disadvantages: Justification as explanation controversial.
	\item Single Token Ablation
\end{itemize}

The following lays out how each of these methods works to achieve the goal of word utility estimation.

\begin{description}
	\item [Performance difference of AI for NLP tasks]
	      Here, a Large Language Model (LLM) or a more specific language processing model is made to run NLP tasks such as text summarization, sentiment detection or question-answering.
	      To find out which words help the AI model the most in performing its tasks, words are methodically omitted from texts and the AI’s performance is recorded.
	      This metric attempts to approximate utility by finding words which, when missing, cause the greatest performance loss in the NLP tasks.
	      Evaluation metrics like Shapley values \cite{wangShapleyExplanationNetworks2021} may be used to measure the impact of missing words
	\item [Transformer attention]
	      The transformer architecture is based on a mechanism called \textit{self-attention}.
	      It allocates the neural network's processing to important parts of the input and thus provides some degree of explainability "out of the box".

	\item [Difference in internal vector representation for AI reading text]
	      This approach words similarly to the above involving an AI model, but instead of measuring the changes in the quality of its output, it measures how much changing the input to the model changes its the internal vector state: AI stores data in vector format, and when performing NLP tasks on texts, there is an internal vector representation.
	      By using various distance metrics, it may be possible to find out which words have the greatest impact on the model’s understanding of a text.
	      Most of these approaches can be done both for individual words and word sequences (n-grams).
	      While individual words are the easiest to examine, sometimes n-grams are insightful for finding sequences of words whose meaning is more than the sum of their parts (idioms and collocations) and which therefore must be learned in separately from their constituents (meaningful English n-grams include e.g. “kick the bucket”, “such that”, “such as”).

	      This also raises the question of what is considered a “word”.
	      A phrase like “such as” can be considered two words if the definition of a word is simply “something separated by a space” or one word if the definition is “a phrase whose meaning cannot be arrived at trivially from knowing the definition of its parts”.
	      In Natural Language Processing, tokenizers break down texts into words, but they typically use the first definition for a word in the case of English.
	      Many non-European language do not use spaces in their spelling (e.g. Japanese, Mandarin Chinese) or use spaces to separate a different unit of text (syllables in Vietnamese, sentences in Thai), making this definition of a word unpractical.
	      In most languages, words can appear in various different forms: Verbs in Spanish are conjugated according to the time and originator of an action, Nouns in German are declined depending on their number and grammatical case.
	      This adds another variable for compiling word lists: Whether the list should consider any different combination of letters as a different word, or whether different forms of the same headword should be viewed as only one word.
\end{description}


\section{Interdependencies Between Components Used}

While the components described above can mostly be used in any combination, there are some important restrictions to keep in mind:

\begin{description}
	\item[Attention as XAI can only be used on transformers]
	\item[Tokenization (and thus selection of word candidates) is only independent on model used in input perturbation approaches]
	      As a direct consequence of this, other XAI mechanisms like attention as explanation are only useful for our purposes if the AI model uses a tokenization approach that somewhat corresponds to human notions of words.
	      If a model uses tokenization approaches where a token is a combination of any three letters, any list obtained that tries to order the tokens by utility, while meaningful, will not be useful for human vocabulary learning.
	      Note that in such cases, we can postprocess the data obtained, by merging the tokens to human-readable words and taking the average or maximum attention score of the AI model's tokens.
	\item[]
\end{description}


