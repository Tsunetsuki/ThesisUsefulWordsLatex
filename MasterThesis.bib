@incollection{alexanderclarkHandbookComputationalLinguistics2010,
  title = {The {{Handbook}} of {{Computational Linguistics}} and {{Natural Language Processing}}: {{Introduction}}},
  booktitle = {The {{Handbook}} of {{Computational Linguistics}} and {{Natural Language Processing}}},
  author = {{Alexander Clark} and {Chris Fox} and {Shalom Lappin}},
  year = {2010},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781444324044.ch},
  pages = {1--8},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781444324044.ch},
  isbn = {978-1-4443-2404-4},
  keywords = {CL and NLP research,Clark's statistical parsing - probabilistic syntactic analysis of sentences in a corpus,compact representations of high level information eluding statistical models,comparing supervised and unsupervised grammar inference,complexity theory studies,computational linguistics (CL) field and NLP,computational resources in time and space computing elements of these classes,current methods employed in CL and NLP,formal language theory,handbook of computational linguistics and natural language processing (NLP),identifying classes of languages and their decidability,primary tools in CL and NLP - natural language properties and processes,shifting - to robust learning and processing systems in large corpora,statistical modeling,symbolic techniques}
}

@misc{allahyariTextSummarizationTechniques2017,
  title = {Text {{Summarization Techniques}}: {{A Brief Survey}}},
  shorttitle = {Text {{Summarization Techniques}}},
  author = {Allahyari, Mehdi and Pouriyeh, Seyedamin and Assefi, Mehdi and Safaei, Saeid and Trippe, Elizabeth D. and Gutierrez, Juan B. and Kochut, Krys},
  year = {2017},
  month = jul,
  number = {arXiv:1707.02268},
  eprint = {1707.02268},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1707.02268},
  urldate = {2025-04-14},
  abstract = {In recent years, there has been a explosion in the amount of text data from a variety of sources. This volume of text is an invaluable source of information and knowledge which needs to be effectively summarized to be useful. In this review, the main approaches to automatic text summarization are described. We review the different processes for summarization and describe the effectiveness and shortcomings of the different methods.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\TH3K3DGQ\\Allahyari et al. - 2017 - Text Summarization Techniques A Brief Survey.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\97GLLRT9\\1707.html}
}

@article{artetxeMassivelyMultilingualSentence2019,
  title = {Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond},
  author = {Artetxe, Mikel and Schwenk, Holger},
  year = {2019},
  journal = {Transactions of the association for computational linguistics},
  volume = {7},
  pages = {597--610},
  publisher = {MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info {\dots}},
  urldate = {2025-01-10},
  file = {C:\Users\lpaal\Zotero\storage\7A3DE4AD\Artetxe and Schwenk - 2019 - Massively multilingual sentence embeddings for zero-shot cross-lingual transfer and beyond.pdf}
}

@article{bauerWordFamilies1993,
  title = {Word Families},
  author = {Bauer, Laurie and Nation, Paul},
  year = {1993},
  journal = {International journal of Lexicography},
  volume = {6},
  number = {4},
  pages = {253--279},
  publisher = {Oxford University Press},
  urldate = {2025-03-17},
  file = {C:\Users\lpaal\Zotero\storage\J9AY5F9V\Bauer and Nation - 1993 - Word families.pdf}
}

@article{brownLanguageModelsAre2020,
  title = {Language Models Are Few-Shot Learners},
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D. and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda},
  year = {2020},
  journal = {Advances in neural information processing systems},
  volume = {33},
  pages = {1877--1901},
  urldate = {2025-01-08},
  file = {C:\Users\lpaal\Zotero\storage\NJCDIF4A\Brown et al. - 2020 - Language models are few-shot learners.pdf}
}

@misc{dahanStateFateSummarization2025,
  title = {The {{State}} and {{Fate}} of {{Summarization Datasets}}: {{A Survey}}},
  shorttitle = {The {{State}} and {{Fate}} of {{Summarization Datasets}}},
  author = {Dahan, Noam and Stanovsky, Gabriel},
  year = {2025},
  month = feb,
  number = {arXiv:2411.04585},
  eprint = {2411.04585},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2411.04585},
  urldate = {2025-04-22},
  abstract = {Automatic summarization has consistently attracted attention due to its versatility and wide application in various downstream tasks. Despite its popularity, we find that annotation efforts have largely been disjointed, and have lacked common terminology. Consequently, it is challenging to discover existing resources or identify coherent research directions. To address this, we survey a large body of work spanning 133 datasets in over 100 languages, creating a novel ontology covering sample properties, collection methods and distribution. With this ontology we make key observations, including the lack in accessible high-quality datasets for low-resource languages, and the field's over-reliance on the news domain and on automatically collected distant supervision. Finally, we make available a web interface that allows users to interact and explore our ontology and dataset collection, as well as a template for a summarization data card, which can be used to streamline future research into a more coherent body of work.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\YJYQ25NE\\Dahan and Stanovsky - 2025 - The State and Fate of Summarization Datasets A Survey.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\JZAVXQY6\\2411.html}
}

@misc{ekstromSequentialRankAgreement2015,
  title = {Sequential Rank Agreement Methods for Comparison of Ranked Lists},
  author = {Ekstr{\o}m, Claus Thorn and Gerds, Thomas Alexander and Jensen, Andreas Kryger and {Brink-Jensen}, Kasper},
  year = {2015},
  month = aug,
  number = {arXiv:1508.06803},
  eprint = {1508.06803},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1508.06803},
  urldate = {2024-12-12},
  abstract = {The comparison of alternative rankings of a set of items is a general and prominent task in applied statistics. Predictor variables are ranked according to magnitude of association with an outcome, prediction models rank subjects according to the personalized risk of an event, and genetic studies rank genes according to their difference in gene expression levels. This article constructs measures of the agreement of two or more ordered lists. We use the standard deviation of the ranks to define a measure of agreement that both provides an intuitive interpretation and can be applied to any number of lists even if some or all are incomplete or censored. The approach can identify change-points in the agreement of the lists and the sequential changes of agreement as a function of the depth of the lists can be compared graphically to a permutation based reference set. The usefulness of these tools are illustrated using gene rankings, and using data from two Danish ovarian cancer studies where we assess the within and between agreement of different statistical classification methods.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Methodology},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\39TUVD5E\\Ekstr√∏m et al. - 2015 - Sequential rank agreement methods for comparison of ranked lists.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\N5RTDRNA\\1508.html}
}

@misc{futeralMOSCARLargescaleMultilingual2024,
  title = {{{mOSCAR}}: {{A Large-scale Multilingual}} and {{Multimodal Document-level Corpus}}},
  shorttitle = {{{mOSCAR}}},
  author = {Futeral, Matthieu and Zebaze, Armel and Suarez, Pedro Ortiz and Abadji, Julien and Lacroix, R{\'e}mi and Schmid, Cordelia and Bawden, Rachel and Sagot, Beno{\^i}t},
  year = {2024},
  month = jun,
  number = {arXiv:2406.08707},
  eprint = {2406.08707},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.08707},
  urldate = {2025-04-01},
  abstract = {Multimodal Large Language Models (mLLMs) are trained on a large amount of text-image data. While most mLLMs are trained on caption-like data only, Alayrac et al. [2022] showed that additionally training them on interleaved sequences of text and images can lead to the emergence of in-context learning capabilities. However, the dataset they used, M3W, is not public and is only in English. There have been attempts to reproduce their results but the released datasets are English-only. In contrast, current multilingual and multimodal datasets are either composed of caption-like only or medium-scale or fully private data. This limits mLLM research for the 7,000 other languages spoken in the world. We therefore introduce mOSCAR, to the best of our knowledge the first large-scale multilingual and multimodal document corpus crawled from the web. It covers 163 languages, 315M documents, 214B tokens and 1.2B images. We carefully conduct a set of filtering and evaluation steps to make sure mOSCAR is sufficiently safe, diverse and of good quality. We additionally train two types of multilingual model to prove the benefits of mOSCAR: (1) a model trained on a subset of mOSCAR and captioning data and (2) a model train on captioning data only. The model additionally trained on mOSCAR shows a strong boost in few-shot learning performance across various multilingual image-text tasks and benchmarks, confirming previous findings for English-only mLLMs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\3FER39RL\\Futeral et al. - 2024 - mOSCAR A Large-scale Multilingual and Multimodal Document-level Corpus.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\FP29QC6T\\2406.html}
}

@article{gholaminejadAcademicVocabularyCollocations2020,
  title = {Academic Vocabulary and Collocations Used in Language Teaching and Applied Linguistics Textbooks: {{A}} Corpus-Based Approach},
  shorttitle = {Academic Vocabulary and Collocations Used in Language Teaching and Applied Linguistics Textbooks},
  author = {Gholaminejad, Razieh and Anani Sarab, Mohammad Reza},
  year = {2020},
  month = jun,
  journal = {Terminology. International Journal of Theoretical and Applied Issues in Specialized Communication},
  volume = {26},
  number = {1},
  pages = {82--107},
  issn = {0929-9971, 1569-9994},
  doi = {10.1075/term.00043.gho},
  urldate = {2025-04-22},
  abstract = {Abstract                            Somewhere between technical and general vocabulary are located those words which are used in formal academic                     contexts with a high frequency across scientific disciplines (               Farrell 1990               ). These are                     referred to as academic vocabulary. Recent findings do not support the adequacy of a single academic wordlist which can equally                     meet the needs of students of all disciplines (               Durrant 2016               ), and this has inspired                     researchers to develop wordlists specific to each discipline. Language Teaching and Applied Linguistics is a discipline which                     often embraces a high number of non-English speaking students for whom it is a demanding task to engage in academic communication                     without having access to a ready-made resource. In the present study, a 10,781,188-word corpus based on textbooks taught in                     thirteen subject areas of this field was compiled. The corpus was characterized by a specified genre and time-span, and a large                     representative scope. It was used to draw up a list of academic words (= terminology) for students of this field. The wordlist,                     which is accompanied by a list of collocations, accounts for approximately 7.1\% of the coverage in the corpus. The findings build                     on the trend toward generation of field-specific academic wordlists, which have significant implications for students,                     instructors, material developers and researchers.},
  copyright = {https://benjamins.com/content/customers/rights},
  langid = {english}
}

@inproceedings{goldhahnBuildingLargeMonolingual2012,
  title = {Building Large Monolingual Dictionaries at the Leipzig Corpora Collection: {{From}} 100 to 200 Languages.},
  shorttitle = {Building Large Monolingual Dictionaries at the Leipzig Corpora Collection},
  booktitle = {{{LREC}}},
  author = {Goldhahn, Dirk and Eckart, Thomas and Quasthoff, Uwe},
  year = {2012},
  volume = {29},
  pages = {31--43},
  urldate = {2025-01-05}
}

@article{heChoosingWordsTeach2019,
  title = {Choosing {{Words}} to {{Teach}}: {{A Novel Method}} for {{Vocabulary Selection}} and {{Its Practical Application}}},
  shorttitle = {Choosing {{Words}} to {{Teach}}},
  author = {He, Xuehong (Stella) and Godfroid, Aline},
  year = {2019},
  month = jun,
  journal = {TESOL Quarterly},
  volume = {53},
  number = {2},
  pages = {348--371},
  issn = {0039-8322, 1545-7249},
  doi = {10.1002/tesq.483},
  urldate = {2025-02-03},
  abstract = {Vocabulary learning materials and vocabulary learning research have a common objective of promoting effective vocabulary instruction (Schmitt, 2008), but in practice vocabulary learning materials tend to reflect materials writers' repertoire and intuition primarily (Tomlinson, 2011). In an effort to develop a stronger interface between research and practice, this article introduces a novel method for word selection based on words' frequency, usefulness, and difficulty (Laufer \& Nation, 2012). The researchers retrieved the frequency of 191 words and collocations targeted in a North American intensive English program from the Corpus of Contemporary American English (               COCA               ) and               COCA               -Academic, and collected usefulness and difficulty ratings from 76 experienced               ESL               instructors. Frequency correlated moderately with usefulness and difficulty, which supported the value of including usefulness and difficulty ratings as word selection criteria. A cluster analysis revealed five distinct groups of target words, which differed in frequency, usefulness, and difficulty. Teaching of the target words could be prioritized according to this sequence. This study introduces a step-by-step approach for materials writers, curriculum designers, and teaching professionals to identify word groupings in a potential list of target words, using a combination of objective and subjective data, with the prospect of creating more effective and more efficacious vocabulary learning materials.},
  langid = {english},
  file = {C:\Users\lpaal\Zotero\storage\PDY2J9NA\He and Godfroid - 2019 - Choosing Words to Teach A Novel Method for Vocabulary Selection and Its Practical Application.pdf}
}

@incollection{hunstonCorpusLinguistics2006a,
  title = {Corpus Linguistics},
  booktitle = {Encyclopedia of Language \& Linguistics (Second Edition)},
  author = {Hunston, S.},
  editor = {Brown, Keith},
  year = {2006},
  edition = {Second Edition},
  pages = {234--248},
  publisher = {Elsevier},
  address = {Oxford},
  doi = {10.1016/B0-08-044854-2/00944-5},
  abstract = {A corpus is an electronically stored collection of texts that is exploited using specialized software. Corpora are used to test hypotheses about language and to provide quantificational data about language use. In addition, they provide an insight into recurring patterns of language that are difficult to observe in other ways. As a result, theories of language based on corpus data are being developed. Corpora have also had an impact on a number of applications of linguistics, including language teaching and translation.},
  isbn = {978-0-08-044854-1},
  keywords = {(unit of) meaning,colligation,collocation,concordance,corpus/corpora,grammar,language teaching,lexical priming,lexis,pattern,phrase/phraseology,probability,translation,variation}
}

@misc{jainAttentionNotExplanation2019,
  title = {Attention Is Not {{Explanation}}},
  author = {Jain, Sarthak and Wallace, Byron C.},
  year = {2019},
  month = may,
  number = {arXiv:1902.10186},
  eprint = {1902.10186},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1902.10186},
  urldate = {2025-04-22},
  abstract = {Attention mechanisms have seen wide adoption in neural NLP models. In addition to improving predictive performance, these are often touted as affording transparency: models equipped with attention provide a distribution over attended-to input units, and this is often presented (at least implicitly) as communicating the relative importance of inputs. However, it is unclear what relationship exists between attention weights and model outputs. In this work, we perform extensive experiments across a variety of NLP tasks that aim to assess the degree to which attention weights provide meaningful `explanations' for predictions. We find that they largely do not. For example, learned attention weights are frequently uncorrelated with gradient-based measures of feature importance, and one can identify very different attention distributions that nonetheless yield equivalent predictions. Our findings show that standard attention modules do not provide meaningful explanations and should not be treated as though they do. Code for all experiments is available at https://github.com/successar/AttentionExplanation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\HIGT7EA7\\Jain and Wallace - 2019 - Attention is not Explanation.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\7IWGR89X\\1902.html}
}

@misc{joshiStateFateLinguistic2021,
  title = {The {{State}} and {{Fate}} of {{Linguistic Diversity}} and {{Inclusion}} in the {{NLP World}}},
  author = {Joshi, Pratik and Santy, Sebastin and Budhiraja, Amar and Bali, Kalika and Choudhury, Monojit},
  year = {2021},
  month = jan,
  number = {arXiv:2004.09095},
  eprint = {2004.09095},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2004.09095},
  urldate = {2025-04-22},
  abstract = {Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the "language agnostic" status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\845VXSN5\\Joshi et al. - 2021 - The State and Fate of Linguistic Diversity and Inclusion in the NLP World.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\BG2XAFS5\\2004.html}
}

@book{jurafskySpeechLanguageProcessing2025,
  title = {Speech and Language Processing: {{An}} Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition with Language Models},
  author = {Jurafsky, Daniel and Martin, James H.},
  year = {2025},
  edition = {3rd},
  publisher = {(unpublished)}
}

@book{jurafskySpeechLanguageProcessing2025a,
  title = {Speech and Language Processing: {{An}} Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition with Language Models},
  author = {Jurafsky, Daniel and Martin, James H.},
  year = {2025},
  edition = {3rd},
  publisher = {(unpublished)}
}

@article{kendallNEWMEASURERANK1938b,
  title = {A {{NEW MEASURE OF RANK CORRELATION}}},
  author = {KENDALL, M. G.},
  year = {1938},
  month = jun,
  journal = {Biometrika},
  volume = {30},
  number = {1-2},
  pages = {81--93},
  issn = {0006-3444},
  doi = {10.1093/biomet/30.1-2.81}
}

@inproceedings{kentonBertPretrainingDeep2019,
  title = {Bert: {{Pre-training}} of Deep Bidirectional Transformers for Language Understanding},
  shorttitle = {Bert},
  booktitle = {Proceedings of {{naacL-HLT}}},
  author = {Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  year = {2019},
  volume = {1},
  pages = {2},
  publisher = {Minneapolis, Minnesota},
  urldate = {2025-01-08},
  file = {C:\Users\lpaal\Zotero\storage\NDUBZTCS\Kenton and Toutanova - 2019 - Bert Pre-training of deep bidirectional transformers for language understanding.pdf}
}

@article{kilgarriffCorpusbasedVocabularyLists2014,
  title = {Corpus-Based Vocabulary Lists for Language Learners for Nine Languages},
  author = {Kilgarriff, Adam and Charalabopoulou, Frieda and Gavrilidou, Maria and Johannessen, Janne Bondi and Khalil, Saussan and Johansson Kokkinakis, Sofie and Lew, Robert and Sharoff, Serge and Vadlapudi, Ravikiran and Volodina, Elena},
  year = {2014},
  month = mar,
  journal = {Language Resources and Evaluation},
  volume = {48},
  number = {1},
  pages = {121--163},
  issn = {1574-0218},
  doi = {10.1007/s10579-013-9251-2},
  urldate = {2025-04-22},
  abstract = {We present the KELLY project and its work on developing monolingual and bilingual word lists for language learning, using corpus methods, for nine languages and thirty-six language pairs. We describe the method and discuss the many challenges encountered. We have loaded the data into an online database to make it accessible for anyone to explore and we present our own first explorations of it. The focus of the paper is thus twofold, covering pedagogical and methodological aspects of the lists' construction, and linguistic aspects of the by-product of the project, the KELLY database.},
  langid = {english},
  keywords = {Corpora,Frequency,Frequency lists,Language learning,Vocabulary},
  file = {C:\Users\lpaal\Zotero\storage\LVQDFPJR\Kilgarriff et al. - 2014 - Corpus-based vocabulary lists for language learners for nine languages.pdf}
}

@article{kokkinakisCorpusbasedApproachesCreation2011,
  title = {Corpus-Based Approaches for the Creation of a Frequency Based Vocabulary List in the {{EU}} Project {{KELLY}}--Issues on Reliability, Validity and Coverage},
  author = {Kokkinakis, Sofie Johansson and Volodina, Elena},
  year = {2011},
  journal = {Proceedings of eLex},
  volume = {2011},
  pages = {129--139},
  urldate = {2025-03-15},
  file = {C:\Users\lpaal\Zotero\storage\6RB3KWGD\Kokkinakis and Volodina - 2011 - Corpus-based approaches for the creation of a frequency based vocabulary list in the EU project KELL.pdf}
}

@phdthesis{leiInterpretableNeuralModels2017,
  type = {Thesis},
  title = {Interpretable Neural Models for Natural Language Processing},
  author = {Lei, Tao},
  year = {2017},
  urldate = {2025-02-26},
  abstract = {The success of neural network models often comes at a cost of interpretability. This thesis addresses the problem by providing justifications behind the model's structure and predictions. In the first part of this thesis, we present a class of sequence operations for text processing. The proposed component generalizes from convolution operations and gated aggregations. As justifications, we relate this component to string kernels, i.e. functions measuring the similarity between sequences, and demonstrate how it encodes the efficient kernel computing algorithm into its structure. The proposed model achieves state-of-the-art or competitive results compared to alternative architectures (such as LSTMs and CNNs) across several NLP applications. In the second part, we learn rationales behind the model's prediction by extracting input pieces as supporting evidence. Rationales are tailored to be short and coherent, yet sufficient for making the same prediction. Our approach combines two modular components, generator and encoder, which are trained to operate well together. The generator specifies a distribution over text fragments as candidate rationales and these are passed through the encoder for prediction. Rationales are never given during training. Instead, the model is regularized by the desiderata for rationales. We demonstrate the effectiveness of this learning framework in applications such multi-aspect sentiment analysis. Our method achieves a performance over 90\% evaluated against manual annotated rationales.},
  copyright = {MIT theses are protected by copyright. They may be viewed, downloaded, or printed from this source but further reproduction or distribution in any format is prohibited without written permission.},
  langid = {english},
  school = {Massachusetts Institute of Technology},
  annotation = {Accepted: 2017-05-11T19:59:27Z},
  file = {C:\Users\lpaal\Zotero\storage\4J9MB24F\Lei - 2017 - Interpretable neural models for natural language processing.pdf}
}

@book{liRoutledgeHandbookSecond2022,
  title = {The Routledge Handbook of Second Language Acquisition and Individual Differences},
  author = {Li, Shaofeng and Hiver, Phil and Papi, Mostafa},
  year = {2022},
  month = apr,
  publisher = {Routledge},
  doi = {10.4324/9781003270546},
  isbn = {978-1-032-21914-1}
}

@article{lisonOpensubtitles2016ExtractingLarge2016,
  title = {Opensubtitles2016: {{Extracting}} Large Parallel Corpora from Movie and Tv Subtitles},
  shorttitle = {Opensubtitles2016},
  author = {Lison, Pierre and Tiedemann, J{\"o}rg},
  year = {2016},
  journal = {Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016)},
  publisher = {European Language Resources Association},
  urldate = {2025-01-05},
  file = {C:\Users\lpaal\Zotero\storage\KP7TULVI\Lison and Tiedemann - 2016 - Opensubtitles2016 Extracting large parallel corpora from movie and tv subtitles.pdf}
}

@misc{liUnderstandingNeuralNetworks2017,
  title = {Understanding {{Neural Networks}} through {{Representation Erasure}}},
  author = {Li, Jiwei and Monroe, Will and Jurafsky, Dan},
  year = {2017},
  month = jan,
  number = {arXiv:1612.08220},
  eprint = {1612.08220},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1612.08220},
  urldate = {2025-02-26},
  abstract = {While neural networks have been successfully applied to many natural language processing tasks, they come at the cost of interpretability. In this paper, we propose a general methodology to analyze and interpret decisions from a neural model by observing the effects on the model of erasing various parts of the representation, such as input word-vector dimensions, intermediate hidden units, or input words. We present several approaches to analyzing the effects of such erasure, from computing the relative difference in evaluation metrics, to using reinforcement learning to erase the minimum set of input words in order to flip a neural model's decision. In a comprehensive analysis of multiple NLP tasks, including linguistic feature classification, sentence-level sentiment analysis, and document level sentiment aspect prediction, we show that the proposed methodology not only offers clear explanations about neural model decisions, but also provides a way to conduct error analysis on neural models.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\C5APXWAP\\Li et al. - 2017 - Understanding Neural Networks through Representation Erasure.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\QGKASWLY\\1612.html}
}

@misc{LlamamodelsModelsLlama3_3,
  title = {Llama-Models/Models/Llama3\_3/{{MODEL}}\_{{CARD}}.Md at Main {$\cdot$} Meta-Llama/Llama-Models},
  journal = {GitHub},
  urldate = {2025-01-08},
  abstract = {Utilities intended for use with Llama models. Contribute to meta-llama/llama-models development by creating an account on GitHub.},
  howpublished = {https://github.com/meta-llama/llama-models/blob/main/models/llama3\_3/MODEL\_CARD.md},
  langid = {english},
  file = {C:\Users\lpaal\Zotero\storage\R3979IAB\MODEL_CARD.html}
}

@misc{lundbergUnifiedApproachInterpreting2017,
  title = {A {{Unified Approach}} to {{Interpreting Model Predictions}}},
  author = {Lundberg, Scott and Lee, Su-In},
  year = {2017},
  month = nov,
  number = {arXiv:1705.07874},
  eprint = {1705.07874},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1705.07874},
  urldate = {2025-04-16},
  abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\G4SC9XLY\\Lundberg and Lee - 2017 - A Unified Approach to Interpreting Model Predictions.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\KPH8HEI7\\1705.html}
}

@inbook{manning84EvaluationRanked2008,
  title = {8.4 {{Evaluation}} of Ranked Retrieval Results},
  booktitle = {Introduction to Information Retrieval},
  year = {2008},
  publisher = {Cambridge University Press},
  address = {New York},
  collaborator = {Manning, Christopher D. and Raghavan, Prabhakar and Sch{\"u}tze, Hinrich},
  isbn = {978-0-521-86571-5},
  lccn = {QA76.9.T48 M26 2008},
  keywords = {Document clustering,Information retrieval,Semantic Web,Text processing (Computer science)},
  annotation = {OCLC: ocn190786122}
}

@book{manningIntroductionInformationRetrieval2008,
  title = {Introduction to Information Retrieval},
  author = {Manning, Christopher D. and Raghavan, Prabhakar and Sch{\"u}tze, Hinrich},
  year = {2008},
  publisher = {Cambridge University Press},
  address = {New York},
  isbn = {978-0-521-86571-5},
  lccn = {QA76.9.T48 M26 2008},
  keywords = {Document clustering,Information retrieval,Semantic Web,Text processing (Computer science)},
  annotation = {OCLC: ocn190786122}
}

@book{michaelwestGeneralServiceList1953,
  title = {A {{General Service List}} of {{English Words}}},
  author = {{Michael West}},
  year = {1953},
  publisher = {{Longman, Green and Co.}},
  address = {London}
}

@book{molnar2025,
  title = {Interpretable Machine Learning. {{A}} Guide for Making Black Box Models Explainable},
  author = {Molnar, Christoph},
  year = {2025},
  edition = {3},
  publisher = {(unpublished)},
  isbn = {978-3-911578-03-5}
}

@incollection{molnarChapter4Methods2025,
  title = {Chapter 4: {{Methods}}},
  booktitle = {Interpretable Machine Learning. {{A}} Guide for Making Black Box Models Explainable},
  author = {Molnar, Christoph},
  year = {2025},
  edition = {3},
  publisher = {(unpublished)},
  isbn = {978-3-911578-03-5}
}

@article{nationVocabularySizeText1997,
  title = {Vocabulary Size, Text Coverage and Word Lists},
  author = {Nation, P.},
  year = {1997},
  journal = {Vocabulary: Description, acquisition and pedagogy/acquisition and pedagogy},
  pages = {6--19},
  urldate = {2025-01-03},
  file = {C:\Users\lpaal\Zotero\storage\4RI9RSFC\nation_waring_97.html}
}

@misc{openaiGPT4TechnicalReport2024,
  title = {{{GPT-4 Technical Report}}},
  author = {OpenAI and Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and Avila, Red and Babuschkin, Igor and Balaji, Suchir and Balcom, Valerie and Baltescu, Paul and Bao, Haiming and Bavarian, Mohammad and Belgum, Jeff and Bello, Irwan and Berdine, Jake and {Bernadett-Shapiro}, Gabriel and Berner, Christopher and Bogdonoff, Lenny and Boiko, Oleg and Boyd, Madelaine and Brakman, Anna-Luisa and Brockman, Greg and Brooks, Tim and Brundage, Miles and Button, Kevin and Cai, Trevor and Campbell, Rosie and Cann, Andrew and Carey, Brittany and Carlson, Chelsea and Carmichael, Rory and Chan, Brooke and Chang, Che and Chantzis, Fotis and Chen, Derek and Chen, Sully and Chen, Ruby and Chen, Jason and Chen, Mark and Chess, Ben and Cho, Chester and Chu, Casey and Chung, Hyung Won and Cummings, Dave and Currier, Jeremiah and Dai, Yunxing and Decareaux, Cory and Degry, Thomas and Deutsch, Noah and Deville, Damien and Dhar, Arka and Dohan, David and Dowling, Steve and Dunning, Sheila and Ecoffet, Adrien and Eleti, Atty and Eloundou, Tyna and Farhi, David and Fedus, Liam and Felix, Niko and Fishman, Sim{\'o}n Posada and Forte, Juston and Fulford, Isabella and Gao, Leo and Georges, Elie and Gibson, Christian and Goel, Vik and Gogineni, Tarun and Goh, Gabriel and {Gontijo-Lopes}, Rapha and Gordon, Jonathan and Grafstein, Morgan and Gray, Scott and Greene, Ryan and Gross, Joshua and Gu, Shixiang Shane and Guo, Yufei and Hallacy, Chris and Han, Jesse and Harris, Jeff and He, Yuchen and Heaton, Mike and Heidecke, Johannes and Hesse, Chris and Hickey, Alan and Hickey, Wade and Hoeschele, Peter and Houghton, Brandon and Hsu, Kenny and Hu, Shengli and Hu, Xin and Huizinga, Joost and Jain, Shantanu and Jain, Shawn and Jang, Joanne and Jiang, Angela and Jiang, Roger and Jin, Haozhun and Jin, Denny and Jomoto, Shino and Jonn, Billie and Jun, Heewoo and Kaftan, Tomer and Kaiser, {\L}ukasz and Kamali, Ali and Kanitscheider, Ingmar and Keskar, Nitish Shirish and Khan, Tabarak and Kilpatrick, Logan and Kim, Jong Wook and Kim, Christina and Kim, Yongjik and Kirchner, Jan Hendrik and Kiros, Jamie and Knight, Matt and Kokotajlo, Daniel and Kondraciuk, {\L}ukasz and Kondrich, Andrew and Konstantinidis, Aris and Kosic, Kyle and Krueger, Gretchen and Kuo, Vishal and Lampe, Michael and Lan, Ikai and Lee, Teddy and Leike, Jan and Leung, Jade and Levy, Daniel and Li, Chak Ming and Lim, Rachel and Lin, Molly and Lin, Stephanie and Litwin, Mateusz and Lopez, Theresa and Lowe, Ryan and Lue, Patricia and Makanju, Anna and Malfacini, Kim and Manning, Sam and Markov, Todor and Markovski, Yaniv and Martin, Bianca and Mayer, Katie and Mayne, Andrew and McGrew, Bob and McKinney, Scott Mayer and McLeavey, Christine and McMillan, Paul and McNeil, Jake and Medina, David and Mehta, Aalok and Menick, Jacob and Metz, Luke and Mishchenko, Andrey and Mishkin, Pamela and Monaco, Vinnie and Morikawa, Evan and Mossing, Daniel and Mu, Tong and Murati, Mira and Murk, Oleg and M{\'e}ly, David and Nair, Ashvin and Nakano, Reiichiro and Nayak, Rajeev and Neelakantan, Arvind and Ngo, Richard and Noh, Hyeonwoo and Ouyang, Long and O'Keefe, Cullen and Pachocki, Jakub and Paino, Alex and Palermo, Joe and Pantuliano, Ashley and Parascandolo, Giambattista and Parish, Joel and Parparita, Emy and Passos, Alex and Pavlov, Mikhail and Peng, Andrew and Perelman, Adam and Peres, Filipe de Avila Belbute and Petrov, Michael and Pinto, Henrique Ponde de Oliveira and Michael and Pokorny and Pokrass, Michelle and Pong, Vitchyr H. and Powell, Tolly and Power, Alethea and Power, Boris and Proehl, Elizabeth and Puri, Raul and Radford, Alec and Rae, Jack and Ramesh, Aditya and Raymond, Cameron and Real, Francis and Rimbach, Kendra and Ross, Carl and Rotsted, Bob and Roussez, Henri and Ryder, Nick and Saltarelli, Mario and Sanders, Ted and Santurkar, Shibani and Sastry, Girish and Schmidt, Heather and Schnurr, David and Schulman, John and Selsam, Daniel and Sheppard, Kyla and Sherbakov, Toki and Shieh, Jessica and Shoker, Sarah and Shyam, Pranav and Sidor, Szymon and Sigler, Eric and Simens, Maddie and Sitkin, Jordan and Slama, Katarina and Sohl, Ian and Sokolowsky, Benjamin and Song, Yang and Staudacher, Natalie and Such, Felipe Petroski and Summers, Natalie and Sutskever, Ilya and Tang, Jie and Tezak, Nikolas and Thompson, Madeleine B. and Tillet, Phil and Tootoonchian, Amin and Tseng, Elizabeth and Tuggle, Preston and Turley, Nick and Tworek, Jerry and Uribe, Juan Felipe Cer{\'o}n and Vallone, Andrea and Vijayvergiya, Arun and Voss, Chelsea and Wainwright, Carroll and Wang, Justin Jay and Wang, Alvin and Wang, Ben and Ward, Jonathan and Wei, Jason and Weinmann, C. J. and Welihinda, Akila and Welinder, Peter and Weng, Jiayi and Weng, Lilian and Wiethoff, Matt and Willner, Dave and Winter, Clemens and Wolrich, Samuel and Wong, Hannah and Workman, Lauren and Wu, Sherwin and Wu, Jeff and Wu, Michael and Xiao, Kai and Xu, Tao and Yoo, Sarah and Yu, Kevin and Yuan, Qiming and Zaremba, Wojciech and Zellers, Rowan and Zhang, Chong and Zhang, Marvin and Zhao, Shengjia and Zheng, Tianhao and Zhuang, Juntang and Zhuk, William and Zoph, Barret},
  year = {2024},
  month = mar,
  number = {arXiv:2303.08774},
  eprint = {2303.08774},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.08774},
  urldate = {2025-01-08},
  abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\4WXF44XZ\\citation-359924624.bib;C\:\\Users\\lpaal\\Zotero\\storage\\MS6P9TPW\\OpenAI et al. - 2024 - GPT-4 Technical Report.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\3QXLC6QX\\2303.html}
}

@inproceedings{ortiz-suarez-etal-2020-monolingual,
  title = {A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  author = {Ortiz Su'arez, Pedro Javier and Romary, Laurent and Sagot, Benoit},
  year = {2020},
  month = jul,
  pages = {1703--1714},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  abstract = {We use the multilingual OSCAR corpus, extracted from Common Crawl via language classification, filtering and cleaning, to train monolingual contextualized word embeddings (ELMo) for five mid-resource languages. We then compare the performance of OSCAR-based and Wikipedia-based ELMo embeddings for these languages on the part-of-speech tagging and parsing tasks. We show that, despite the noise in the Common-Crawl-based OSCAR data, embeddings trained on OSCAR perform much better than monolingual embeddings trained on Wikipedia. They actually equal or improve the current state of the art in tagging and parsing for all five languages. In particular, they also improve over multilingual Wikipedia-based contextual embeddings (multilingual BERT), which almost always constitutes the previous state of the art, thereby showing that the benefit of a larger, more diverse corpus surpasses the cross-lingual benefit of multilingual embedding architectures.}
}

@article{pellicerDataAugmentationTechniques2023,
  title = {Data Augmentation Techniques in Natural Language Processing},
  author = {Pellicer, Lucas Francisco Amaral Orosco and Ferreira, Taynan Maier and Costa, Anna Helena Reali},
  year = {2023},
  month = jan,
  journal = {Applied Soft Computing},
  volume = {132},
  pages = {109803},
  issn = {1568-4946},
  doi = {10.1016/j.asoc.2022.109803},
  urldate = {2025-01-05},
  abstract = {Data Augmentation (DA) methods -- a family of techniques designed for synthetic generation of training data -- have shown remarkable results in various Deep Learning and Machine Learning tasks. Despite its widespread and successful adoption within the computer vision community, DA techniques designed for natural language processing (NLP) tasks have exhibited much slower advances and limited success in achieving performance gains. As a consequence, with the exception of applications of back-translation to machine translation tasks, these techniques have not been as thoroughly explored by the wider NLP community. Recent research on the subject still lacks a proper practical understanding of the relationship between the various existing DA methods. The connection between DA methods and several important aspects of its outputs, such as lexical diversity and semantic fidelity, is also still poorly understood. In this work, we perform a comprehensive study of NLP DA techniques, comparing their relative performance under different settings. We analyze the quality of the synthetic data generated, evaluate its performance gains and compare all of these aspects to previous existing DA procedures.},
  keywords = {Back-translation,Data augmentation,Machine learning,Natural language processing},
  file = {C:\Users\lpaal\Zotero\storage\LRTRTDHQ\S1568494622008523.html}
}

@article{qaiserTextMiningUse2018,
  title = {Text Mining: Use of {{TF-IDF}} to Examine the Relevance of Words to Documents},
  shorttitle = {Text Mining},
  author = {Qaiser, Shahzad and Ali, Ramsha},
  year = {2018},
  journal = {International Journal of Computer Applications},
  volume = {181},
  number = {1},
  pages = {25--29},
  urldate = {2025-01-03}
}

@article{qaiserTextMiningUse2018a,
  title = {Text Mining: {{Use}} of {{TF-IDF}} to Examine the Relevance of Words to Documents},
  author = {Qaiser, Shahzad and Ali, Ramsha},
  year = {2018},
  month = jul,
  journal = {International Journal of Computer Applications},
  volume = {181},
  doi = {10.5120/ijca2018917395}
}

@article{radevIntroductionSpecialIssue2002,
  title = {Introduction to the Special Issue on Summarization},
  author = {Radev, Dragomir and Hovy, Eduard and McKeown, Kathleen},
  year = {2002},
  journal = {Computational linguistics},
  volume = {28},
  number = {4},
  pages = {399--408},
  urldate = {2025-04-14},
  file = {C:\Users\lpaal\Zotero\storage\TSUBGAVC\Radev et al. - 2002 - Introduction to the special issue on summarization.pdf}
}

@article{radfordLanguageModelsAre2019,
  title = {Language Models Are Unsupervised Multitask Learners},
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year = {2019},
  journal = {OpenAI blog},
  volume = {1},
  number = {8},
  pages = {9},
  urldate = {2025-01-08},
  file = {C:\Users\lpaal\Zotero\storage\44LNTG4C\Radford et al. - 2019 - Language models are unsupervised multitask learners.pdf}
}

@incollection{rajaraman2011data,
  title = {Data Mining},
  booktitle = {Mining of Massive Datasets},
  author = {Rajaraman, Anand and Ullman, Jeffrey D.},
  year = {2011},
  pages = {1--17},
  publisher = {Cambridge University Press}
}

@misc{reimersMakingMonolingualSentence2020,
  title = {Making {{Monolingual Sentence Embeddings Multilingual}} Using {{Knowledge Distillation}}},
  author = {Reimers, Nils and Gurevych, Iryna},
  year = {2020},
  month = oct,
  number = {arXiv:2004.09813},
  eprint = {2004.09813},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2004.09813},
  urldate = {2025-01-13},
  abstract = {We present an easy and efficient method to extend existing sentence embedding models to new languages. This allows to create multilingual versions from previously monolingual models. The training is based on the idea that a translated sentence should be mapped to the same location in the vector space as the original sentence. We use the original (monolingual) model to generate sentence embeddings for the source language and then train a new system on translated sentences to mimic the original model. Compared to other methods for training multilingual sentence embeddings, this approach has several advantages: It is easy to extend existing models with relatively few samples to new languages, it is easier to ensure desired properties for the vector space, and the hardware requirements for training is lower. We demonstrate the effectiveness of our approach for 50+ languages from various language families. Code to extend sentence embeddings models to more than 400 languages is publicly available.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\YC6333GB\\Reimers and Gurevych - 2020 - Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\5QZMKGWF\\2004.html}
}

@misc{ribeiroWhyShouldTrust2016,
  title = {"{{Why Should I Trust You}}?": {{Explaining}} the {{Predictions}} of {{Any Classifier}}},
  shorttitle = {"{{Why Should I Trust You}}?},
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  year = {2016},
  month = aug,
  number = {arXiv:1602.04938},
  eprint = {1602.04938},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1602.04938},
  urldate = {2025-04-16},
  abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\MC2GHSDK\\Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predictions of Any Classifier.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\Q25V6JRN\\1602.html}
}

@book{rich1983artificial,
  title = {Artificial Intelligence},
  author = {Rich, E.},
  year = {1983},
  series = {Artificial Intelligence},
  publisher = {McGraw-Hill},
  isbn = {978-0-07-052261-9}
}

@article{savickyMeasuresWordCommonness2002,
  title = {Measures of {{Word Commonness}}},
  author = {Savick{\'y}, Petr and Hlav{\'a}cov{\'a}, Jaroslava},
  year = {2002},
  month = dec,
  journal = {Journal of Quantitative Linguistics},
  volume = {9},
  number = {3},
  pages = {215--231},
  issn = {0929-6174, 1744-5035},
  doi = {10.1076/jqul.9.3.215.14124},
  urldate = {2025-03-15},
  langid = {english}
}

@misc{schwenkCCMatrixMiningBillions2020,
  title = {{{CCMatrix}}: {{Mining Billions}} of {{High-Quality Parallel Sentences}} on the {{WEB}}},
  shorttitle = {{{CCMatrix}}},
  author = {Schwenk, Holger and Wenzek, Guillaume and Edunov, Sergey and Grave, Edouard and Joulin, Armand},
  year = {2020},
  month = may,
  number = {arXiv:1911.04944},
  eprint = {1911.04944},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1911.04944},
  urldate = {2025-01-10},
  abstract = {We show that margin-based bitext mining in a multilingual sentence space can be applied to monolingual corpora of billions of sentences. We are using ten snapshots of a curated common crawl corpus (Wenzek et al., 2019) totalling 32.7 billion unique sentences. Using one unified approach for 38 languages, we were able to mine 4.5 billions parallel sentences, out of which 661 million are aligned with English. 20 language pairs have more then 30 million parallel sentences, 112 more then 10 million, and most more than one million, including direct alignments between many European or Asian languages. To evaluate the quality of the mined bitexts, we train NMT systems for most of the language pairs and evaluate them on TED, WMT and WAT test sets. Using our mined bitexts only and no human translated parallel data, we achieve a new state-of-the-art for a single system on the WMT'19 test set for translation between English and German, Russian and Chinese, as well as German/French. In particular, our English/German system outperforms the best single one by close to 4 BLEU points and is almost on pair with best WMT'19 evaluation system which uses system combination and back-translation. We also achieve excellent results for distant languages pairs like Russian/Japanese, outperforming the best submission at the 2019 workshop on Asian Translation (WAT).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\B9BHRYBT\\Schwenk et al. - 2020 - CCMatrix Mining Billions of High-Quality Parallel Sentences on the WEB.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\R96A292X\\1911.html}
}

@article{searleMindsBrainsPrograms1980,
  title = {Minds, Brains, and Programs},
  author = {Searle, John R.},
  year = {1980},
  journal = {Behavioral and brain sciences},
  volume = {3},
  number = {3},
  pages = {417--424},
  publisher = {Cambridge University Press},
  urldate = {2025-04-22},
  file = {C:\Users\lpaal\Zotero\storage\B9IIBRAK\Searle - 1980 - Minds, brains, and programs.pdf}
}

@article{spearmanCorrelationCalculatedFaulty1910,
  title = {Correlation Calculated from Faulty Data},
  author = {Spearman, Charles},
  year = {1910},
  journal = {British journal of psychology},
  volume = {3},
  number = {3},
  pages = {271},
  publisher = {Cambridge University Press},
  urldate = {2024-12-12}
}

@inproceedings{suarezAsynchronousPipelineProcessing2019,
  title = {Asynchronous Pipeline for Processing Huge Corpora on Medium to Low Resource Infrastructures},
  booktitle = {7th {{Workshop}} on the {{Challenges}} in the {{Management}} of {{Large Corpora}} ({{CMLC-7}})},
  author = {Su{\'a}rez, Pedro Javier Ortiz and Sagot, Beno{\^i}t and Romary, Laurent},
  year = {2019},
  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},
  urldate = {2025-05-02},
  file = {C:\Users\lpaal\Zotero\storage\5L3PPFQE\Su√°rez et al. - 2019 - Asynchronous pipeline for processing huge corpora on medium to low resource infrastructures.pdf}
}

@inproceedings{tiedemannOPUSMTbuildingOpenTranslation2020,
  title = {{{OPUS-MT}}--Building Open Translation Services for the World},
  booktitle = {Proceedings of the 22nd Annual Conference of the {{European Association}} for {{Machine Translation}}},
  author = {Tiedemann, J{\"o}rg and Thottingal, Santhosh},
  year = {2020},
  pages = {479--480},
  urldate = {2025-01-07},
  file = {C:\Users\lpaal\Zotero\storage\PDFTFL9X\Tiedemann and Thottingal - 2020 - OPUS-MT‚Äìbuilding open translation services for the world.pdf}
}

@article{tjuatjaLLMsExhibitHumanlike2024,
  title = {Do {{LLMs Exhibit Human-like Response Biases}}? {{A Case Study}} in {{Survey Design}}},
  shorttitle = {Do Llms Exhibit Human-like Response Biases?},
  author = {Tjuatja, Lindia and Chen, Valerie and Wu, Tongshuang and Talwalkwar, Ameet and Neubig, Graham},
  year = {2024},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {12},
  pages = {1011--1026},
  publisher = {MIT Press 255 Main Street, 9th Floor, Cambridge, Massachusetts 02142, USA {\dots}},
  urldate = {2025-04-06},
  file = {C:\Users\lpaal\Zotero\storage\X5U8IY8J\Tjuatja et al. - 2024 - Do llms exhibit human-like response biases a case study in survey design.pdf}
}

@article{vaswani2017attention,
  title = {Attention Is {{All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  year = {2017},
  journal = {Advances in neural information processing systems},
  volume = {30}
}

@article{viloneNotionsExplainabilityEvaluation2021,
  title = {Notions of Explainability and Evaluation Approaches for Explainable Artificial Intelligence},
  author = {Vilone, Giulia and Longo, Luca},
  year = {2021},
  journal = {Information Fusion},
  volume = {76},
  pages = {89--106},
  issn = {1566-2535},
  doi = {10.1016/j.inffus.2021.05.009},
  abstract = {Explainable Artificial Intelligence (XAI) has experienced a significant growth over the last few years. This is due to the widespread application of machine learning, particularly deep learning, that has led to the development of highly accurate models that lack explainability and interpretability. A plethora of methods to tackle this problem have been proposed, developed and tested, coupled with several studies attempting to define the concept of explainability and its evaluation. This systematic review contributes to the body of knowledge by clustering all the scientific studies via a hierarchical system that classifies theories and notions related to the concept of explainability and the evaluation approaches for XAI methods. The structure of this hierarchy builds on top of an exhaustive analysis of existing taxonomies and peer-reviewed scientific material. Findings suggest that scholars have identified numerous notions and requirements that an explanation should meet in order to be easily understandable by end-users and to provide actionable information that can inform decision making. They have also suggested various approaches to assess to what degree machine-generated explanations meet these demands. Overall, these approaches can be clustered into human-centred evaluations and evaluations with more objective metrics. However, despite the vast body of knowledge developed around the concept of explainability, there is not a general consensus among scholars on how an explanation should be defined, and how its validity and reliability assessed. Eventually, this review concludes by critically discussing these gaps and limitations, and it defines future research directions with explainability as the starting component of any artificial intelligent system.},
  keywords = {Evaluation methods,Explainable artificial intelligence,Notions of explainability}
}

@misc{wangShapleyExplanationNetworks2021,
  title = {Shapley {{Explanation Networks}}},
  author = {Wang, Rui and Wang, Xiaoqian and Inouye, David I.},
  year = {2021},
  month = apr,
  number = {arXiv:2104.02297},
  eprint = {2104.02297},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2104.02297},
  urldate = {2025-01-03},
  abstract = {Shapley values have become one of the most popular feature attribution explanation methods. However, most prior work has focused on post-hoc Shapley explanations, which can be computationally demanding due to its exponential time complexity and preclude model regularization based on Shapley explanations during training. Thus, we propose to incorporate Shapley values themselves as latent representations in deep models thereby making Shapley explanations first-class citizens in the modeling paradigm. This intrinsic explanation approach enables layer-wise explanations, explanation regularization of the model during training, and fast explanation computation at test time. We define the Shapley transform that transforms the input into a Shapley representation given a specific function. We operationalize the Shapley transform as a neural network module and construct both shallow and deep networks, called ShapNets, by composing Shapley modules. We prove that our Shallow ShapNets compute the exact Shapley values and our Deep ShapNets maintain the missingness and accuracy properties of Shapley values. We demonstrate on synthetic and real-world datasets that our ShapNets enable layer-wise Shapley explanations, novel Shapley regularizations during training, and fast computation while maintaining reasonable performance. Code is available at https://github.com/inouye-lab/ShapleyExplanationNetworks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\SWYJTPC4\\Wang et al. - 2021 - Shapley Explanation Networks.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\VD999ALK\\2104.html}
}

@article{webberSimilarityMeasureIndefinite2010,
  title = {A Similarity Measure for Indefinite Rankings},
  author = {Webber, William and Moffat, Alistair and Zobel, Justin},
  year = {2010},
  month = nov,
  journal = {ACM Trans. Inf. Syst.},
  volume = {28},
  number = {4},
  pages = {20:1--20:38},
  issn = {1046-8188},
  doi = {10.1145/1852102.1852106},
  urldate = {2024-12-23},
  abstract = {Ranked lists are encountered in research and daily life and it is often of interest to compare these lists even when they are incomplete or have only some members in common. An example is document rankings returned for the same query by different search engines. A measure of the similarity between incomplete rankings should handle nonconjointness, weight high ranks more heavily than low, and be monotonic with increasing depth of evaluation; but no measure satisfying all these criteria currently exists. In this article, we propose a new measure having these qualities, namely rank-biased overlap (RBO). The RBO measure is based on a simple probabilistic user model. It provides monotonicity by calculating, at a given depth of evaluation, a base score that is non-decreasing with additional evaluation, and a maximum score that is nonincreasing. An extrapolated score can be calculated between these bounds if a point estimate is required. RBO has a parameter which determines the strength of the weighting to top ranks. We extend RBO to handle tied ranks and rankings of different lengths. Finally, we give examples of the use of the measure in comparing the results produced by public search engines and in assessing retrieval systems in the laboratory.},
  file = {C:\Users\lpaal\Zotero\storage\EXCWL67C\Webber et al. - 2010 - A similarity measure for indefinite rankings.pdf}
}

@misc{WhatMachineLearning,
  title = {What {{Is Machine Learning}} ({{ML}})? {\textbar} {{IBM}}},
  urldate = {2025-02-26},
  howpublished = {https://www.ibm.com/think/topics/machine-learning}
}

@misc{wiegreffeAttentionNotNot2019,
  title = {Attention Is Not Not {{Explanation}}},
  author = {Wiegreffe, Sarah and Pinter, Yuval},
  year = {2019},
  month = sep,
  number = {arXiv:1908.04626},
  eprint = {1908.04626},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1908.04626},
  urldate = {2025-04-22},
  abstract = {Attention mechanisms play a central role in NLP systems, especially within recurrent neural network (RNN) models. Recently, there has been increasing interest in whether or not the intermediate representations offered by these modules may be used to explain the reasoning for a model's prediction, and consequently reach insights regarding the model's decision-making process. A recent paper claims that `Attention is not Explanation' (Jain and Wallace, 2019). We challenge many of the assumptions underlying this work, arguing that such a claim depends on one's definition of explanation, and that testing it needs to take into account all elements of the model, using a rigorous experimental design. We propose four alternative tests to determine when/whether attention can be used as explanation: a simple uniform-weights baseline; a variance calibration based on multiple random seed runs; a diagnostic framework using frozen weights from pretrained models; and an end-to-end adversarial attention training protocol. Each allows for meaningful interpretation of attention mechanisms in RNN models. We show that even when reliable adversarial distributions can be found, they don't perform well on the simple diagnostic, indicating that prior work does not disprove the usefulness of attention mechanisms for explainability.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\Y7XZX8CQ\\Wiegreffe and Pinter - 2019 - Attention is not not Explanation.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\A69JMGGW\\1908.html}
}

@article{xodabandeDevelopingValidatingMidfrequency2023,
  title = {Developing and Validating a Mid-Frequency Word List for Chemistry: A Corpus-Based Approach Using Big Data},
  shorttitle = {Developing and Validating a Mid-Frequency Word List for Chemistry},
  author = {Xodabande, Ismail and Atai, Mahmood Reza and Hashemi, Mohammad R. and Thompson, Paul},
  year = {2023},
  month = oct,
  journal = {Asian-Pacific Journal of Second and Foreign Language Education},
  volume = {8},
  number = {1},
  pages = {32},
  issn = {2363-5169},
  doi = {10.1186/s40862-023-00205-5},
  urldate = {2025-04-22},
  abstract = {Given the importance of specialized vocabulary in scientific communication and academic discourse, there is a growing need to create wordlists to address the~vocabulary-learning needs of university students and researchers in different subject areas. The current study analyzed a corpus of chemistry research articles (with~278 million running words) to establish a mid-frequency vocabulary list for this field. Using frequency, range, and dispersion criteria, the study identified 560 lemmas in the fourth to the~ninth British National Corpus/Corpus of Contemporary American English~(BNC/COCA) lists that provided 6.4\% coverage of all words in the corpus. The list was validated using specialized and general corpora, and the results confirmed the value and relevance of the items for chemistry. Moreover, for using the list for pedagogical goals, the vocabulary items were divided into five bands based on their coverage and importance. The 100 words in the first band were the most important mid-frequent vocabulary in chemistry, as they provided 3.05\% coverage. The study highlights the significant contribution of mid-frequency words in research articles and the findings have implications for using large corpora as a big data source in identifying specialized and field-specific vocabulary.},
  keywords = {Academic vocabulary,Big data,Chemistry,Corpus linguistics,EAP/ESP vocabulary,Mid-frequency vocabulary,Research article,Wordlist},
  file = {C\:\\Users\\lpaal\\Zotero\\storage\\8325FK7A\\Xodabande et al. - 2023 - Developing and validating a mid-frequency word list for chemistry a corpus-based approach using big.pdf;C\:\\Users\\lpaal\\Zotero\\storage\\SDD5J9WP\\s40862-023-00205-5.html}
}
